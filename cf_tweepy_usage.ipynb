{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the FREE sandbox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cf_tweepy import scrape_tweets_sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTHENTICATION SUCCESS!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-03 14:35:08</td>\n",
       "      <td>1334506460873699331</td>\n",
       "      <td>My site update with premium 3rd party tested C...</td>\n",
       "      <td>My site update with premium 3rd party tested C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-03 14:30:22</td>\n",
       "      <td>1334505258144428033</td>\n",
       "      <td>Oat milk is now sending its troops into the ch...</td>\n",
       "      <td>Oat milk is now sending its troops into the ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-03 14:27:43</td>\n",
       "      <td>1334504592944619520</td>\n",
       "      <td>@Statist_Simp Nah it's great.\\n\\nEven before i...</td>\n",
       "      <td>@Statist_Simp Nah it's great.  Even before i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-03 14:09:10</td>\n",
       "      <td>1334499924310945794</td>\n",
       "      <td>RT @Sonic1938: Much like humans, cows have str...</td>\n",
       "      <td>RT @Sonic1938: Much like humans, cows have str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-03 14:04:10</td>\n",
       "      <td>1334498664681791489</td>\n",
       "      <td>@TheDullahMan1 @Darth_Brexit_ Can i have those...</td>\n",
       "      <td>@TheDullahMan1 @Darth_Brexit_ Can i have those...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                   id  \\\n",
       "0 2020-12-03 14:35:08  1334506460873699331   \n",
       "1 2020-12-03 14:30:22  1334505258144428033   \n",
       "2 2020-12-03 14:27:43  1334504592944619520   \n",
       "3 2020-12-03 14:09:10  1334499924310945794   \n",
       "4 2020-12-03 14:04:10  1334498664681791489   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  My site update with premium 3rd party tested C...   \n",
       "1  Oat milk is now sending its troops into the ch...   \n",
       "2  @Statist_Simp Nah it's great.\\n\\nEven before i...   \n",
       "3  RT @Sonic1938: Much like humans, cows have str...   \n",
       "4  @TheDullahMan1 @Darth_Brexit_ Can i have those...   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0  My site update with premium 3rd party tested C...  \n",
       "1  Oat milk is now sending its troops into the ch...  \n",
       "2  @Statist_Simp Nah it's great.  Even before i w...  \n",
       "3  RT @Sonic1938: Much like humans, cows have str...  \n",
       "4  @TheDullahMan1 @Darth_Brexit_ Can i have those...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authorize\n",
    "sand_box = scrape_tweets_sandbox(consumer_key='EcOZufuRLcf1PR2G7CSFkcfGa',\n",
    "                                consumer_secret='Z6uScbjgSzuOf0o5wfRGdWsIpeqY1GfAKlhXGwpiv6Xm36uo5Z')\n",
    "# Params\n",
    "query_list = ['Vegan milk', 'Vegan meat']\n",
    "count = 1000\n",
    "lang = 'en'\n",
    "\n",
    "df = sand_box.scrape(query_list,count,lang)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PREMIUM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cf_tweepy import scrape_tweets_full_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTHENTICATION SUCCESS!!!\n",
      "failed on_status, {'message': 'Request exceeds account’s current package request limits. Please upgrade your package and retry or contact Twitter about enterprise access.', 'sent': '2020-12-03T14:36:31+00:00', 'transactionId': '0057307d008cd96c'}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'tweets_df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-faaf96416c6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmaxResults\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msand_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfromDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoDate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxResults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Cauliflower_Ankit\\scrapping_HENKEL\\cf_tweepy\\cf_tweepy\\cf_tweepy.py\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(self, environment_name, query, fromDate, toDate, maxResults)\u001b[0m\n\u001b[0;32m    130\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'failed on_status,'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'tweets_df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "sand_box = scrape_tweets_full_archive(consumer_key='EcOZufuRLcf1PR2G7CSFkcfGa',\n",
    "                                consumer_secret='Z6uScbjgSzuOf0o5wfRGdWsIpeqY1GfAKlhXGwpiv6Xm36uo5Z')\n",
    "# Params\n",
    "environment_name = 'Discourse'\n",
    "query = 'tierhaltungsform'\n",
    "fromDate='200603210000'\n",
    "toDate = '202011010000'   \n",
    "maxResults= 500\n",
    "\n",
    "df = sand_box.scrape(environment_name, query, fromDate, toDate, maxResults)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
